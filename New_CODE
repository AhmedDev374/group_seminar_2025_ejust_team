"""
pill_gui.py

Full GUI + training + augmentation + evaluation system for pill image classification,
with an added Test tab for uploading a single image and seeing prediction + probability bar chart.

Place this file next to your 'pills' folder.

This version fixes the "numpy() is only available when eager execution is enabled" error by:
 - clearing Keras session before (re)loading or building models
 - enabling eager execution for training/evaluation (tf.config.run_functions_eagerly(True))
   and restoring it afterwards (if possible)
 - keeping training/evaluation in worker threads but scheduling UI updates on the main loop
"""

import os
import threading
import time
import math
import numpy as np

# Force quieter TF logs if desired (optional)
os.environ.setdefault("TF_CPP_MIN_LOG_LEVEL", "1")

# Use Agg backend for matplotlib to avoid GUI backend conflicts when plotting from threads
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

from PIL import Image, ImageTk
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
import itertools
import tkinter as tk
from tkinter import ttk, filedialog, messagebox

# TensorFlow / Keras
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
from tensorflow.keras import backend as K

# ---------------------------
# Config (use absolute dataset path by default)
# ---------------------------
BASE_DIR = os.path.abspath(os.path.dirname(__file__))
DEFAULT_DATA_DIR = os.path.join(BASE_DIR, "pills")   # absolute path to pills folder
IMAGE_SIZE = (128, 128)
BATCH_SIZE = 32
DEFAULT_EPOCHS = 12
TARGET_AUG_PER_CLASS = 500
MODEL_PATH = os.path.join(BASE_DIR, "pill_model.h5")
HISTORY_PATH = os.path.join(BASE_DIR, "history.npy")

# ---------------------------
# Small helpers
# ---------------------------
def debug_dataset_path(path):
    """Prints debug info about dataset path and returns absolute path."""
    abs_path = os.path.abspath(path)
    print("=== DATASET DEBUG ===")
    print("Script BASE_DIR:", BASE_DIR)
    print("Requested path:", path)
    print("Absolute path:", abs_path)
    exists = os.path.exists(abs_path)
    print("Exists:", exists)
    if exists and os.path.isdir(abs_path):
        entries = sorted(os.listdir(abs_path))
        print("Top-level entries (folders/files):", entries)
        for d in entries:
            p = os.path.join(abs_path, d)
            if os.path.isdir(p):
                imgs = [f for f in os.listdir(p) if f.lower().endswith(('.jpg','.jpeg','.png'))]
                print(f" - class '{d}': {len(imgs)} image(s) -> {imgs[:8]}")
    print("=====================\n")
    return abs_path

# ---------------------------
# AUGMENTATION (uses ALL images in class folder)
# ---------------------------
def augment_dataset(data_dir=None, target_count=TARGET_AUG_PER_CLASS, verbose=True):
    if data_dir is None:
        data_dir = DEFAULT_DATA_DIR
    data_dir = os.path.abspath(data_dir)
    debug_dataset_path(data_dir)

    if not os.path.isdir(data_dir):
        print(f"[augment] Dataset folder not found: {data_dir}")
        return False

    aug_gen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.15,
        zoom_range=0.3,
        brightness_range=(0.5, 1.4),
        horizontal_flip=True,
        fill_mode='nearest'
    )

    classes = [d for d in sorted(os.listdir(data_dir)) if os.path.isdir(os.path.join(data_dir, d))]
    if not classes:
        print(f"[augment] No class subfolders found in {data_dir}.")
        return False

    for cls in classes:
        class_path = os.path.join(data_dir, cls)
        imgs = [f for f in sorted(os.listdir(class_path)) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        if len(imgs) == 0:
            if verbose:
                print(f"[augment] No images found in {class_path}, skipping.")
            continue

        existing_count = len(imgs)
        to_create = max(0, target_count - existing_count)
        if to_create == 0:
            if verbose:
                print(f"[augment] Class {cls} already has {existing_count} images — skipping augmentation.")
            continue

        print(f"[augment] Generating {to_create} images for class '{cls}' ...")

        # Distribute augmentation across all existing images in this class
        created = 0
        per_image = math.ceil(to_create / len(imgs))

        for img_name in imgs:
            if created >= to_create:
                break
            base_path = os.path.join(class_path, img_name)
            try:
                img = load_img(base_path, target_size=IMAGE_SIZE)
            except Exception as e:
                print(f"[augment] Failed to load {base_path}: {e}")
                continue

            x = img_to_array(img)
            x = x.reshape((1,) + x.shape)

            gen = aug_gen.flow(x, batch_size=1, save_to_dir=class_path,
                               save_prefix=f"{cls}_aug", save_format='jpg')
            for _ in range(per_image):
                if created >= to_create:
                    break
                try:
                    next(gen)
                    created += 1
                    if created % 50 == 0:
                        print(f"[augment] {created}/{to_create} created for {cls}")
                except Exception as e:
                    print("[augment] generator stopped:", e)
                    break

        print(f"[augment] Done {cls}: created {created} images.")

    print("[augment] All done.")
    return True

# ---------------------------
# Model builder
# ---------------------------
def build_model(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), num_classes=4):
    K.clear_session()
    model = Sequential([
        Conv2D(32, (3,3), activation='relu', input_shape=input_shape),
        BatchNormalization(),
        MaxPooling2D(2,2),

        Conv2D(64, (3,3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(2,2),

        Conv2D(128, (3,3), activation='relu'),
        BatchNormalization(),
        MaxPooling2D(2,2),

        Flatten(),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# ---------------------------
# GLOBAL STATE
# ---------------------------
GLOBAL_STATE = {
    "history": None,
    "class_indices": None,
    "labels": None,
    "conf_matrix": None,
    "report": None,
    "model": None,
    "test_conf_matrix": None,
    "test_report": None,
    "test_accuracy": None,
    "test_per_class_acc": None
}

# ---------------------------
# Small utilities for TF eager-mode toggling
# ---------------------------
def enable_eager_mode():
    try:
        tf.config.run_functions_eagerly(True)
    except Exception:
        # older TF compatibility
        try:
            tf.config.experimental_run_functions_eagerly(True)
        except Exception:
            pass

def disable_eager_mode():
    try:
        tf.config.run_functions_eagerly(False)
    except Exception:
        try:
            tf.config.experimental_run_functions_eagerly(False)
        except Exception:
            pass

# ---------------------------
# Training function (supports epochs=0 for evaluation-only)
# ---------------------------
def train_model(epochs=DEFAULT_EPOCHS, update_callback=None, data_dir=None):
    """
    If epochs <= 0: will only prepare generators and evaluate existing model (no fit)
    update_callback: callable(msg) to safely send messages to UI (prefer main-thread scheduling)
    """
    if data_dir is None or data_dir.strip() == "":
        data_dir = DEFAULT_DATA_DIR
    data_dir = os.path.abspath(data_dir)
    debug_dataset_path(data_dir)

    def log(msg):
        print(msg)
        if update_callback:
            try:
                update_callback(msg)
            except Exception:
                # swallow UI callback errors
                print("[train] update_callback failed for msg:", msg)

    if not os.path.isdir(data_dir):
        log(f"[train] ERROR: dataset folder not found: {data_dir}")
        return False

    log("[train] Preparing generators...")

    train_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.15,
        zoom_range=0.25,
        brightness_range=(0.6, 1.4),
        horizontal_flip=True,
        fill_mode='nearest',
        validation_split=0.2
    )
    val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

    # wrap the call in try/except and ensure path is absolute
    try:
        train_generator = train_datagen.flow_from_directory(
            data_dir,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='training',
            shuffle=True
        )
        val_generator = val_datagen.flow_from_directory(
            data_dir,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            subset='validation',
            shuffle=False
        )
    except Exception as e:
        log(f"[train] flow_from_directory error: {e}")
        return False

    if train_generator.num_classes == 0:
        log("[train] ERROR: Found 0 classes or 0 images. Please check the dataset path and directory structure.")
        return False

    GLOBAL_STATE["class_indices"] = train_generator.class_indices
    labels = {v:k for k,v in GLOBAL_STATE["class_indices"].items()}
    GLOBAL_STATE["labels"] = labels
    num_classes = len(train_generator.class_indices)
    log(f"[train] Detected classes: {train_generator.class_indices}")

    # ensure clean session before load/build
    try:
        K.clear_session()
    except Exception:
        pass

    # Build or load model
    model = None
    if os.path.exists(MODEL_PATH):
        try:
            # load model (clear session done above)
            model = load_model(MODEL_PATH)
            log("[train] Existing model loaded from disk.")
        except Exception as e:
            log(f"[train] Failed loading existing model, rebuilding: {e}")
            model = build_model(num_classes=num_classes)
    else:
        model = build_model(num_classes=num_classes)

    # Enable eager execution for training/evaluation to avoid numpy() on tensors error.
    # We enable only for the duration of fit/eval; restore afterwards.
    enable_eager_mode()
    try:
        if epochs and epochs > 0:
            checkpoint = ModelCheckpoint(MODEL_PATH, monitor='val_accuracy', verbose=1,
                                         save_best_only=True, mode='max')
            reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)
            early_stop = EarlyStopping(monitor='val_accuracy', patience=6, verbose=1, restore_best_weights=True)

            log("[train] Starting training ...")
            history = model.fit(
                train_generator,
                validation_data=val_generator,
                epochs=epochs,
                callbacks=[checkpoint, reduce_lr, early_stop]
            )
            GLOBAL_STATE["history"] = history.history
            try:
                np.save(HISTORY_PATH, history.history)
            except Exception as e:
                log(f"[train] Failed to save history: {e}")
            GLOBAL_STATE["model"] = model
        else:
            log("[train] Skipping training (epochs <= 0). Using existing model for evaluation if available.")
            GLOBAL_STATE["model"] = model

        log("[train] Training finished. Evaluating on validation set...")

        # Evaluate on validation generator
        try:
            val_steps = int(np.ceil(val_generator.samples / val_generator.batch_size))
            val_generator.reset()
            preds = model.predict(val_generator, steps=val_steps, verbose=1)
            y_pred = np.argmax(preds, axis=1)
            y_true = val_generator.classes

            cm = confusion_matrix(y_true, y_pred)
            GLOBAL_STATE["conf_matrix"] = cm
            class_labels = [k for k,_ in sorted(train_generator.class_indices.items(), key=lambda x: x[1])]
            report = classification_report(y_true, y_pred, target_names=class_labels, digits=4)
            GLOBAL_STATE["report"] = report

            log("[train] Confusion Matrix:\n" + np.array2string(cm))
            log("[train] Classification Report:\n" + report)
        except Exception as e:
            log(f"[train] Evaluation failed: {e}")
            return False
    finally:
        # restore non-eager mode for performance if API supports it
        try:
            disable_eager_mode()
        except Exception:
            pass

    return True

# ---------------------------
# Evaluate test folder (subfolders)
# ---------------------------
def evaluate_test_folder(test_dir, update_callback=None):
    if GLOBAL_STATE.get("model") is None:
        if os.path.exists(MODEL_PATH):
            try:
                K.clear_session()
                GLOBAL_STATE["model"] = load_model(MODEL_PATH)
            except Exception as e:
                if update_callback:
                    update_callback(f"[test] Failed to load model from disk: {e}")
                return False
        else:
            if update_callback:
                update_callback("[test] No model available (train first or load model).")
            return False

    test_dir = os.path.abspath(test_dir)
    debug_dataset_path(test_dir)

    if not os.path.isdir(test_dir):
        if update_callback:
            update_callback(f"[test] Test folder not found: {test_dir}")
        return False

    classes = sorted([d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))])
    if not classes:
        if update_callback:
            update_callback("[test] Test folder must contain class subfolders (e.g. pill1, pill2...).")
        return False

    test_gen = ImageDataGenerator(rescale=1./255)
    try:
        test_flow = test_gen.flow_from_directory(
            test_dir,
            target_size=IMAGE_SIZE,
            batch_size=BATCH_SIZE,
            class_mode='categorical',
            shuffle=False
        )
    except Exception as e:
        if update_callback:
            update_callback(f"[test] flow_from_directory error: {e}")
        return False

    # enable eager for predict
    enable_eager_mode()
    try:
        model = GLOBAL_STATE["model"]
        steps = int(np.ceil(test_flow.samples / test_flow.batch_size))
        test_flow.reset()
        preds = model.predict(test_flow, steps=steps, verbose=1)
        y_pred = np.argmax(preds, axis=1)
        y_true = test_flow.classes

        cm = confusion_matrix(y_true, y_pred)
        report = classification_report(y_true, y_pred, target_names=[k for k,_ in sorted(test_flow.class_indices.items(), key=lambda x: x[1])], digits=4)
        acc = accuracy_score(y_true, y_pred)

        per_class_acc = []
        for i in range(cm.shape[0]):
            total = cm[i,:].sum()
            tp = cm[i,i]
            per_class_acc.append(float(tp/total) if total>0 else 0.0)

        GLOBAL_STATE["test_conf_matrix"] = cm
        GLOBAL_STATE["test_report"] = report
        GLOBAL_STATE["test_accuracy"] = float(acc)
        ordered_labels = [k for k,_ in sorted(test_flow.class_indices.items(), key=lambda x: x[1])]
        GLOBAL_STATE["test_per_class_acc"] = { ordered_labels[i]: per_class_acc[i] for i in range(len(per_class_acc)) }

        if update_callback:
            update_callback(f"[test] Accuracy: {acc*100:.2f}%")
            update_callback("[test] Confusion Matrix:\n" + np.array2string(cm))
            update_callback("[test] Classification Report:\n" + report)
    finally:
        try:
            disable_eager_mode()
        except Exception:
            pass

    return True

# ---------------------------
# Visualization helpers
# ---------------------------
def plot_history(history_dict, save_path="training_graph.png"):
    fig, axes = plt.subplots(1,2, figsize=(10,4))
    if 'accuracy' in history_dict:
        axes[0].plot(history_dict['accuracy'], label='train_acc')
    if 'val_accuracy' in history_dict:
        axes[0].plot(history_dict['val_accuracy'], label='val_acc')
    axes[0].set_title("Accuracy")
    axes[0].legend()
    if 'loss' in history_dict:
        axes[1].plot(history_dict['loss'], label='train_loss')
    if 'val_loss' in history_dict:
        axes[1].plot(history_dict['val_loss'], label='val_loss')
    axes[1].set_title("Loss")
    axes[1].legend()
    plt.tight_layout()
    fig.savefig(save_path)
    plt.close(fig)
    return save_path

def plot_confusion_matrix(cm, classes, save_path="conf_matrix.png", normalize=False):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    fig, ax = plt.subplots(figsize=(6,5))
    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    ax.figure.colorbar(im, ax=ax)
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           xticklabels=classes, yticklabels=classes,
           title="Confusion Matrix",
           ylabel='True label',
           xlabel='Predicted label')
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right")
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        val = cm[i, j]
        s = f"{val:.2f}" if normalize else f"{int(val)}"
        ax.text(j, i, s, ha="center", va="center", color="white" if val > thresh else "black")
    fig.tight_layout()
    fig.savefig(save_path)
    plt.close(fig)
    return save_path

def plot_test_class_accuracy(per_class_acc_dict, save_path="test_class_accuracy.png"):
    labels = list(per_class_acc_dict.keys())
    accs = [per_class_acc_dict[l] for l in labels]
    fig, ax = plt.subplots(figsize=(6,4))
    ax.bar(labels, [a*100 for a in accs])
    ax.set_xlabel("Class")
    ax.set_ylabel("Accuracy (%)")
    ax.set_title("Per-class Accuracy on Test Set")
    plt.xticks(rotation=45, ha="right")
    plt.tight_layout()
    fig.savefig(save_path)
    plt.close(fig)
    return save_path

# ---------------------------
# Prediction helpers (single image)
# ---------------------------
def predict_image(model, image_path, top_k=3):
    img = Image.open(image_path).convert('RGB').resize(IMAGE_SIZE)
    arr = np.array(img) / 255.0
    arr = np.expand_dims(arr, axis=0)
    # enable eager briefly for predict
    enable_eager_mode()
    try:
        probs = model.predict(arr)[0]
    finally:
        try:
            disable_eager_mode()
        except Exception:
            pass
    labels = GLOBAL_STATE.get("labels", {})
    pairs = [(labels.get(i, str(i)), float(probs[i])) for i in range(len(probs))]
    pairs_sorted = sorted(pairs, key=lambda x: x[1], reverse=True)
    return pairs_sorted[:top_k], probs  # return probs vector for plotting too

# ---------------------------
# GUI
# ---------------------------
class PillApp:
    def __init__(self, root):
        self.root = root
        root.title("Pill Classifier — Fixed (eager) ")
        root.geometry("980x760")

        self.notebook = ttk.Notebook(root)
        self.frame_train = ttk.Frame(self.notebook)
        self.frame_predict = ttk.Frame(self.notebook)
        self.frame_test = ttk.Frame(self.notebook)
        self.frame_perf = ttk.Frame(self.notebook)

        self.notebook.add(self.frame_train, text="Train")
        self.notebook.add(self.frame_predict, text="Predict / Test")
        self.notebook.add(self.frame_test, text="Single Image Test")
        self.notebook.add(self.frame_perf, text="Performance")
        self.notebook.pack(fill='both', expand=True)

        self._build_train_tab()
        self._build_predict_tab()
        self._build_test_tab()
        self._build_perf_tab()

        # Try to load saved model & infer labels from DEFAULT_DATA_DIR if available
        if os.path.exists(MODEL_PATH) and os.path.isdir(DEFAULT_DATA_DIR):
            classes = sorted([d for d in os.listdir(DEFAULT_DATA_DIR) if os.path.isdir(os.path.join(DEFAULT_DATA_DIR, d))])
            GLOBAL_STATE["labels"] = {i:c for i,c in enumerate(classes)}
            GLOBAL_STATE["class_indices"] = {c:i for i,c in enumerate(classes)}
            try:
                # clear session before load
                K.clear_session()
                GLOBAL_STATE["model"] = load_model(MODEL_PATH)
                self.append_log_threadsafe("Loaded existing model and inferred labels from default dataset folder.")
            except Exception:
                GLOBAL_STATE["model"] = None

    # Thread-safe log: schedule actual UI insertion on main thread
    def append_log_threadsafe(self, msg):
        # schedule on main thread
        self.root.after(0, lambda: self._append_log(msg))

    def _append_log(self, msg):
        ts = time.strftime("%H:%M:%S")
        try:
            self.text_log.insert('end', f"[{ts}] {msg}\n")
            self.text_log.see('end')
        except Exception:
            print(f"[{ts}] {msg}")
        print(msg)

    # TRAIN TAB
    def _build_train_tab(self):
        frame = self.frame_train
        left = ttk.Frame(frame, padding=10)
        left.pack(side='left', fill='y')

        ttk.Label(left, text="Dataset folder (optional):").pack(anchor='w')
        self.entry_data = ttk.Entry(left, width=50)
        self.entry_data.insert(0, DEFAULT_DATA_DIR)
        self.entry_data.pack(anchor='w', pady=4)

        ttk.Button(left, text="Browse", command=self.browse_dataset).pack(pady=4, anchor='w')
        ttk.Button(left, text=f"Auto-augment (create {TARGET_AUG_PER_CLASS} images/class)", command=self._on_augment_click).pack(pady=6, anchor='w')

        ttk.Label(left, text="Epochs:").pack(anchor='w', pady=(8,0))
        self.spin_epochs = ttk.Spinbox(left, from_=1, to=200, width=6)
        self.spin_epochs.set(DEFAULT_EPOCHS)
        self.spin_epochs.pack(anchor='w', pady=2)

        ttk.Button(left, text="Start Training", command=self._on_train_click).pack(pady=8, anchor='w')
        ttk.Button(left, text="Load & Evaluate Existing Model", command=self._on_load_existing).pack(pady=4, anchor='w')

        right = ttk.Frame(frame, padding=10)
        right.pack(side='left', fill='both', expand=True)
        ttk.Label(right, text="Console / Status:").pack(anchor='w')
        self.text_log = tk.Text(right, height=30)
        self.text_log.pack(fill='both', expand=True)

    def browse_dataset(self):
        folder = filedialog.askdirectory()
        if folder:
            folder = os.path.abspath(folder)
            self.entry_data.delete(0, 'end')
            self.entry_data.insert(0, folder)

    def _on_augment_click(self):
        data_dir = self.entry_data.get().strip() or DEFAULT_DATA_DIR
        t = threading.Thread(target=self._augment_thread, args=(data_dir,), daemon=True)
        t.start()

    def _augment_thread(self, data_dir):
        self.append_log_threadsafe("Starting augmentation...")
        ok = augment_dataset(data_dir, TARGET_AUG_PER_CLASS, verbose=True)
        if ok:
            self.append_log_threadsafe("Augmentation complete.")
        else:
            self.append_log_threadsafe("Augmentation failed or nothing to do. Check dataset folder.")

    def _on_train_click(self):
        data_dir = self.entry_data.get().strip() or DEFAULT_DATA_DIR
        try:
            epochs = int(self.spin_epochs.get())
        except:
            epochs = DEFAULT_EPOCHS
        t = threading.Thread(target=self._train_thread, args=(data_dir, epochs), daemon=True)
        t.start()

    def _train_thread(self, data_dir, epochs):
        self.append_log_threadsafe("Training thread started.")
        ok = train_model(epochs=epochs, update_callback=self.append_log_threadsafe, data_dir=data_dir)
        if ok:
            self.append_log_threadsafe("Training finished successfully.")
            self.root.after(0, self._update_performance_tab)
            self.root.after(0, lambda: messagebox.showinfo("Train", "Training finished successfully (best model saved to disk)."))
        else:
            self.append_log_threadsafe("Training did not run (see earlier errors).")

    def _on_load_existing(self):
        if not os.path.exists(MODEL_PATH):
            messagebox.showerror("Error", f"No saved model found at {MODEL_PATH}")
            return
        try:
            K.clear_session()
            GLOBAL_STATE["model"] = load_model(MODEL_PATH)
            data_dir = self.entry_data.get().strip() or DEFAULT_DATA_DIR
            data_dir = os.path.abspath(data_dir)
            if os.path.isdir(data_dir):
                classes = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])
            else:
                classes = sorted([d for d in os.listdir(DEFAULT_DATA_DIR) if os.path.isdir(os.path.join(DEFAULT_DATA_DIR, d))])
            GLOBAL_STATE["labels"] = {i:c for i,c in enumerate(classes)}
            GLOBAL_STATE["class_indices"] = {c:i for i,c in enumerate(classes)}
            self.append_log_threadsafe("Model loaded from disk and labels inferred.")
            self.append_log_threadsafe("Evaluating model on validation set...")

            t = threading.Thread(target=lambda: train_model(epochs=0, update_callback=self.append_log_threadsafe, data_dir=data_dir), daemon=True)
            t.start()
        except Exception as e:
            messagebox.showerror("Error loading model", str(e))

    # PREDICT / TEST TAB (batch & predict)
    def _build_predict_tab(self):
        frame = self.frame_predict
        top = ttk.Frame(frame, padding=8)
        top.pack(fill='x')
        ttk.Button(top, text="Load Image & Predict", command=self._on_load_predict).pack(side='left', padx=6)
        ttk.Button(top, text="Batch Predict Folder", command=self._on_batch_predict).pack(side='left', padx=6)
        ttk.Button(top, text="Evaluate Test Folder", command=self._on_evaluate_test_folder).pack(side='left', padx=6)
        ttk.Button(top, text="Reload Model", command=self._on_reload_model).pack(side='left', padx=6)

        main = ttk.Frame(frame)
        main.pack(fill='both', expand=True, padx=8, pady=8)

        self.lbl_pred_image = ttk.Label(main)
        self.lbl_pred_image.pack(side='left', padx=10, pady=10)

        right = ttk.Frame(main, padding=10)
        right.pack(side='left', fill='both', expand=True)
        ttk.Label(right, text="Prediction results:").pack(anchor='w')
        self.txt_pred = tk.Text(right, height=12, width=60)
        self.txt_pred.pack(fill='both', expand=True)

        ttk.Label(right, text="Batch results:").pack(anchor='w', pady=(8,0))
        self.tree = ttk.Treeview(right, columns=('file','pred','conf'), show='headings', height=8)
        self.tree.heading('file', text='File')
        self.tree.heading('pred', text='Predicted')
        self.tree.heading('conf', text='Confidence')
        self.tree.column('file', width=300)
        self.tree.column('pred', width=120)
        self.tree.column('conf', width=100)
        self.tree.pack(fill='both', expand=True)

    def _on_reload_model(self):
        if not os.path.exists(MODEL_PATH):
            messagebox.showerror("Error", "Model file not found.")
            return
        try:
            K.clear_session()
            GLOBAL_STATE["model"] = load_model(MODEL_PATH)
            self.append_log_threadsafe("Model reloaded from disk.")
            messagebox.showinfo("Model", "Model reloaded from disk.")
        except Exception as e:
            messagebox.showerror("Error", str(e))

    def _on_load_predict(self):
        if GLOBAL_STATE.get("model") is None:
            if os.path.exists(MODEL_PATH):
                K.clear_session()
                GLOBAL_STATE["model"] = load_model(MODEL_PATH)
            else:
                messagebox.showerror("Model missing", "No model loaded or saved. Train or load a model first.")
                return

        fpath = filedialog.askopenfilename(filetypes=[("Images","*.jpg *.png *.jpeg")])
        if not fpath:
            return

        pil = Image.open(fpath).convert('RGB')
        display_img = pil.resize((256,256))
        tkimg = ImageTk.PhotoImage(display_img)
        self.lbl_pred_image.configure(image=tkimg)
        self.lbl_pred_image.image = tkimg

        preds, _ = predict_image(GLOBAL_STATE["model"], fpath, top_k=3)
        self.txt_pred.delete('1.0', 'end')
        self.txt_pred.insert('end', f"File: {os.path.basename(fpath)}\n\n")
        for idx,(label,conf) in enumerate(preds, start=1):
            self.txt_pred.insert('end', f"{idx}. {label} — {conf*100:.2f}%\n")

    def _on_batch_predict(self):
        if GLOBAL_STATE.get("model") is None:
            if os.path.exists(MODEL_PATH):
                K.clear_session()
                GLOBAL_STATE["model"] = load_model(MODEL_PATH)
            else:
                messagebox.showerror("Model missing", "Train or load model first.")
                return

        folder = filedialog.askdirectory()
        if not folder:
            return

        for i in self.tree.get_children():
            self.tree.delete(i)

        files = [os.path.join(folder,f) for f in os.listdir(folder) if f.lower().endswith(('.jpg','.jpeg','.png'))]
        for f in files:
            try:
                preds, _ = predict_image(GLOBAL_STATE["model"], f, top_k=1)
                label, conf = preds[0]
                self.tree.insert('', 'end', values=(os.path.basename(f), label, f"{conf*100:.2f}%"))
            except Exception as e:
                self.tree.insert('', 'end', values=(os.path.basename(f), "ERROR", str(e)))

    def _on_evaluate_test_folder(self):
        folder = filedialog.askdirectory()
        if not folder:
            return
        t = threading.Thread(target=self._evaluate_test_thread, args=(folder,), daemon=True)
        t.start()

    def _evaluate_test_thread(self, folder):
        self.append_log_threadsafe("Starting test evaluation...")
        ok = evaluate_test_folder(folder, update_callback=self.append_log_threadsafe)
        if ok:
            self.append_log_threadsafe("Test evaluation finished.")
            self.root.after(0, self._update_performance_tab)
            acc = GLOBAL_STATE.get("test_accuracy")
            report = GLOBAL_STATE.get("test_report")
            def show_results():
                self.txt_pred.delete('1.0', 'end')
                self.txt_pred.insert('end', f"Test folder: {folder}\nAccuracy: {acc*100:.2f}%\n\n")
                self.txt_pred.insert('end', "Classification Report:\n")
                self.txt_pred.insert('end', report)
            self.root.after(0, show_results)
        else:
            self.append_log_threadsafe("Test evaluation failed. Check logs.")

    # NEW: SINGLE IMAGE TEST TAB
    def _build_test_tab(self):
        frame = self.frame_test
        top = ttk.Frame(frame, padding=8)
        top.pack(fill='x')
        ttk.Label(top, text="Single Image Test (upload one image)").pack(side='left', padx=6)
        ttk.Button(top, text="Upload Image", command=self._on_test_upload).pack(side='left', padx=6)
        ttk.Button(top, text="Reload Model", command=self._on_reload_model).pack(side='left', padx=6)

        main = ttk.Frame(frame, padding=8)
        main.pack(fill='both', expand=True)

        left = ttk.Frame(main)
        left.pack(side='left', padx=10)
        self.test_img_label = ttk.Label(left)
        self.test_img_label.pack()

        right = ttk.Frame(main)
        right.pack(side='left', fill='both', expand=True, padx=10)
        ttk.Label(right, text="Prediction:").pack(anchor='w')
        self.test_pred_label = ttk.Label(right, text="No prediction yet", font=("Arial", 14))
        self.test_pred_label.pack(anchor='w', pady=6)

        ttk.Label(right, text="Probability distribution:").pack(anchor='w', pady=(8,0))
        self.test_prob_canvas = ttk.Label(right)  # we'll place a small matplotlib image here
        self.test_prob_canvas.pack(fill='both', expand=True)

    def _on_test_upload(self):
        if GLOBAL_STATE.get("model") is None:
            if os.path.exists(MODEL_PATH):
                K.clear_session()
                GLOBAL_STATE["model"] = load_model(MODEL_PATH)
            else:
                messagebox.showerror("Model missing", "No model loaded or saved. Train or load a model first.")
                return

        fpath = filedialog.askopenfilename(filetypes=[("Images","*.jpg *.png *.jpeg")])
        if not fpath:
            return

        pil = Image.open(fpath).convert('RGB')
        preview = pil.resize((300,300))
        tkimg = ImageTk.PhotoImage(preview)
        self.test_img_label.configure(image=tkimg)
        self.test_img_label.image = tkimg

        preds, probs = predict_image(GLOBAL_STATE["model"], fpath, top_k=3)
        top_label, top_conf = preds[0]
        self.test_pred_label.config(text=f"{top_label} — {top_conf*100:.2f}%")

        labels = GLOBAL_STATE.get("labels", {})
        if not labels:
            if os.path.isdir(DEFAULT_DATA_DIR):
                classes = sorted([d for d in os.listdir(DEFAULT_DATA_DIR) if os.path.isdir(os.path.join(DEFAULT_DATA_DIR, d))])
                labels = {i:c for i,c in enumerate(classes)}
                GLOBAL_STATE["labels"] = labels

        if labels:
            max_idx = max(labels.keys())
            expected_len = max_idx + 1
            if len(probs) == expected_len:
                probs_display = probs
            elif len(probs) >= expected_len:
                probs_display = probs[:expected_len]
            else:
                probs_display = np.zeros(expected_len)
                probs_display[:len(probs)] = probs
            label_names = [labels[i] for i in sorted(labels.keys())]
        else:
            label_names = [p[0] for p in preds]
            probs_display = np.array([p[1] for p in preds])

        try:
            fig, ax = plt.subplots(figsize=(4,2.4))
            ax.bar(label_names, probs_display*100)
            ax.set_ylabel("Probability (%)")
            ax.set_ylim(0,100)
            plt.xticks(rotation=45, ha="right")
            plt.tight_layout()
            tmp_path = os.path.join(BASE_DIR, "temp_prob.png")
            fig.savefig(tmp_path)
            plt.close(fig)
            img = Image.open(tmp_path).resize((420,180))
            tkprob = ImageTk.PhotoImage(img)
            self.test_prob_canvas.configure(image=tkprob)
            self.test_prob_canvas.image = tkprob
        except Exception as e:
            self.append_log_threadsafe(f"[test] Failed to plot probabilities: {e}")

    # PERFORMANCE TAB
    def _build_perf_tab(self):
        frame = self.frame_perf
        top = ttk.Frame(frame)
        top.pack(fill='x', pady=6)
        ttk.Button(top, text="Refresh Performance", command=self._update_performance_tab).pack(side='left', padx=6)
        ttk.Button(top, text="Save Report to file", command=self._save_report).pack(side='left')

        mid = ttk.Frame(frame)
        mid.pack(fill='both', expand=True)

        left = ttk.Frame(mid)
        left.pack(side='left', padx=8, pady=8)
        self.lbl_graph = ttk.Label(left)
        self.lbl_graph.pack()
        self.lbl_test_graph = ttk.Label(left)
        self.lbl_test_graph.pack(pady=(8,0))

        right = ttk.Frame(mid)
        right.pack(side='left', fill='both', expand=True, padx=8)
        self.lbl_cm = ttk.Label(right)
        self.lbl_cm.pack(pady=6)
        ttk.Label(right, text="Classification Report:").pack(anchor='w')
        self.txt_report = tk.Text(right, width=60)
        self.txt_report.pack(fill='both', expand=True)

    def _update_performance_tab(self):
        history = GLOBAL_STATE.get("history")
        if history is None and os.path.exists(HISTORY_PATH):
            try:
                history = np.load(HISTORY_PATH, allow_pickle=True).item()
                GLOBAL_STATE["history"] = history
            except Exception:
                history = None

        if history:
            graph_path = plot_history(history, save_path=os.path.join(BASE_DIR,"training_graph.png"))
            img = Image.open(graph_path).resize((480, 320))
            tkimg = ImageTk.PhotoImage(img)
            self.lbl_graph.configure(image=tkimg)
            self.lbl_graph.image = tkimg
        else:
            self.lbl_graph.configure(image='', text="No training history available.")

        cm = GLOBAL_STATE.get("test_conf_matrix") or GLOBAL_STATE.get("conf_matrix")
        labels = []
        if GLOBAL_STATE.get("labels"):
            labels = [GLOBAL_STATE["labels"][i] for i in sorted(GLOBAL_STATE["labels"].keys())]

        if cm is not None and len(labels) == cm.shape[0]:
            cm_path = plot_confusion_matrix(cm, classes=labels, save_path=os.path.join(BASE_DIR,"conf_matrix.png"))
            img = Image.open(cm_path).resize((360, 300))
            tkimg = ImageTk.PhotoImage(img)
            self.lbl_cm.configure(image=tkimg)
            self.lbl_cm.image = tkimg
        else:
            self.lbl_cm.configure(text="Confusion matrix not computed yet.")

        test_per_class = GLOBAL_STATE.get("test_per_class_acc")
        if test_per_class:
            try:
                test_graph = plot_test_class_accuracy(test_per_class, save_path=os.path.join(BASE_DIR,"test_class_accuracy.png"))
                img = Image.open(test_graph).resize((480,180))
                tkimg = ImageTk.PhotoImage(img)
                self.lbl_test_graph.configure(image=tkimg)
                self.lbl_test_graph.image = tkimg
            except Exception as e:
                print("Failed to plot test class accuracy:", e)
        else:
            self.lbl_test_graph.configure(image='', text="No test results to display.")

        report = GLOBAL_STATE.get("test_report") or GLOBAL_STATE.get("report")
        if report:
            self.txt_report.delete('1.0', 'end')
            self.txt_report.insert('end', report)
        else:
            self.txt_report.delete('1.0', 'end')
            self.txt_report.insert('end', "No classification report available yet.")

    def _save_report(self):
        report = GLOBAL_STATE.get("test_report") or GLOBAL_STATE.get("report")
        if not report:
            messagebox.showinfo("No report", "No classification report to save.")
            return
        f = filedialog.asksaveasfilename(defaultextension=".txt", filetypes=[("Text","*.txt")])
        if not f:
            return
        with open(f, "w") as fh:
            fh.write(report)
        messagebox.showinfo("Saved", f"Report saved to {f}")

# ---------------------------
# Main
# ---------------------------
def main():
    root = tk.Tk()
    app = PillApp(root)
    root.mainloop()

if __name__ == "__main__":
    main()
